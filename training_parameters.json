{
    "dataset_dir": "plans",
    "tokenizer_file": "logistics_tokenizer.json",
    "per_device_train_batch_size": 8,
    "per_device_eval_batch_size": 8,
    "num_train_epochs": 6,
    "output_dir": "training_gpt",
    "seed": 7,
    "checkpointing_steps": "epochs"
}
