{
    "dataset_dir": "plans",
    "tokenizer_file": "logistics_tokenizer.json",
    "per_device_train_batch_size": 16,
    "per_device_eval_batch_size": 16,
    "num_train_epochs": 7,
    "output_dir": "training_gpt",
    "seed": 7,
    "checkpointing_steps": "epoch",
    "save_total_limit": 5
}
